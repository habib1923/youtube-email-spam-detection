{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de1d6958",
        "outputId": "d1b4466e-5119-4dae-b531-666f410fe9f8"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCkumJ7ZuH6E",
        "outputId": "787da389-046c-4654-994e-4716410b16a9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *"
      ],
      "metadata": {
        "id": "Cri2dEIXtWw4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder\\\n",
        ".appName(\"Mon premier application Spark\")\\\n",
        ".config(\"spark.memory.offHeap.enabled\",\"true\")\\\n",
        ".config(\"spark.memory.offHeap.size\",\"10g\")\\\n",
        ".getOrCreate()"
      ],
      "metadata": {
        "id": "wqkWLjckthGf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "fichier = \"/content/spam.csv\"\n",
        "\n",
        "df = pd.read_csv(fichier, encoding='latin-1')\n",
        "print(df.head())\n",
        "print(df.columns)\n",
        "\n",
        "assert 'texte' in df.columns or 'v2' in df.columns, \"La colonne 'texte' ou 'v2' est manquante !\"\n",
        "assert 'label' in df.columns or 'v1' in df.columns, \"La colonne 'label' ou 'v1' est manquante !\"\n",
        "\n",
        "\n",
        "print(\" Donn√©es charg√©es correctement !\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrLusG3YuZ25",
        "outputId": "31e57e2a-819c-42d2-d798-f8147491a5d5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     v1                                                 v2 Unnamed: 2  \\\n",
            "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
            "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
            "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
            "\n",
            "  Unnamed: 3 Unnamed: 4  \n",
            "0        NaN        NaN  \n",
            "1        NaN        NaN  \n",
            "2        NaN        NaN  \n",
            "3        NaN        NaN  \n",
            "4        NaN        NaN  \n",
            "Index(['v1', 'v2', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], dtype='object')\n",
            " Donn√©es charg√©es correctement !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark_df = spark.createDataFrame(df)\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"v2\", outputCol=\"tokens\")\n",
        "\n",
        "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"mots_utiles\")\n",
        "\n",
        "hashingTF = HashingTF(inputCol=\"mots_utiles\", outputCol=\"rawFeatures\", numFeatures=20000)\n",
        "\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idf])\n",
        "model = pipeline.fit(spark_df)\n",
        "df_prepared = model.transform(spark_df)\n",
        "df_prepared.select(\"v2\", \"tokens\", \"mots_utiles\", \"features\").show(5, truncate=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roT84OVuwAUp",
        "outputId": "600cb4fc-b32d-4a68-832b-7197d61e71d6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|                  v2|              tokens|         mots_utiles|            features|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|Go until jurong p...|[go, until, juron...|[go, jurong, poin...|(20000,[740,750,1...|\n",
            "|Ok lar... Joking ...|[ok, lar..., joki...|[ok, lar..., joki...|(20000,[2630,2645...|\n",
            "|Free entry in 2 a...|[free, entry, in,...|[free, entry, 2, ...|(20000,[587,1169,...|\n",
            "|U dun say so earl...|[u, dun, say, so,...|[u, dun, say, ear...|(20000,[3783,8419...|\n",
            "|Nah I don't think...|[nah, i, don't, t...|[nah, think, goes...|(20000,[3163,3340...|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = df_prepared.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "print(\"Taille du dataset d'entra√Ænement :\", train_df.count())\n",
        "print(\"Taille du dataset de test :\", test_df.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZAvwAwuwg4a",
        "outputId": "4b5529d4-7c4a-49c6-dc93-5f3767a4e3dd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taille du dataset d'entra√Ænement : 4518\n",
            "Taille du dataset de test : 1054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.feature import StringIndexer, IndexToString\n",
        "\n",
        "indexer = StringIndexer(inputCol=\"v1\", outputCol=\"label\")\n",
        "indexed_train_df = indexer.fit(train_df).transform(train_df)\n",
        "indexed_test_df = indexer.fit(test_df).transform(test_df)\n",
        "\n",
        "\n",
        "nb = NaiveBayes(featuresCol=\"features\", labelCol=\"label\", smoothing=1.0, modelType=\"multinomial\")\n",
        "\n",
        "nb_model = nb.fit(indexed_train_df)\n",
        "\n",
        "print(\"‚úÖ Mod√®le Naive Bayes entra√Æn√© !\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u41Jx_cgwvfo",
        "outputId": "d4147023-d44c-456e-f7ca-d61034ef2393"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Mod√®le Naive Bayes entra√Æn√© !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=\"label\",\n",
        "    numTrees=50,\n",
        "    maxDepth=10\n",
        ")\n",
        "\n",
        "\n",
        "rf_model = rf.fit(indexed_train_df)\n",
        "\n",
        "print(\"‚úÖ Mod√®le Random Forest entra√Æn√© !\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0beVCjvHxM0l",
        "outputId": "e2e3db1b-45f5-4c4f-92e5-3b38fefa8ca9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Mod√®le Random Forest entra√Æn√© !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=\"label\",\n",
        "    maxIter=50,\n",
        "    regParam=0.01\n",
        ")\n",
        "\n",
        "lr_model = lr.fit(indexed_train_df)\n",
        "\n",
        "print(\"‚úÖ Mod√®le Logistic Regression entra√Æn√© !\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbZiutUSxjqX",
        "outputId": "4f1185a7-b9b4-4ec4-a3d1-a1418666dabc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Mod√®le Logistic Regression entra√Æn√© !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Assurez-vous que indexed_test_df est disponible (cr√©√© dans la cellule Naive Bayes)\n",
        "\n",
        "# Evaluators\n",
        "evaluator_accuracy = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "evaluator_precision = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
        "\n",
        "evaluator_recall = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
        "\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "\n",
        "# --- Predictions ---\n",
        "# Effectuer les pr√©dictions sur le DataFrame de test index√© (qui contient la colonne 'label')\n",
        "pred_nb = nb_model.transform(indexed_test_df)\n",
        "pred_rf = rf_model.transform(indexed_test_df)\n",
        "pred_lr = lr_model.transform(indexed_test_df)\n",
        "\n",
        "# --- Calcul des m√©triques pour chaque mod√®le ---\n",
        "def evaluate_model(pred):\n",
        "    return {\n",
        "        \"Accuracy\": evaluator_accuracy.evaluate(pred),\n",
        "        \"Precision\": evaluator_precision.evaluate(pred),\n",
        "        \"Recall\": evaluator_recall.evaluate(pred),\n",
        "        \"F1-score\": evaluator_f1.evaluate(pred)\n",
        "    }\n",
        "\n",
        "metrics_nb = evaluate_model(pred_nb)\n",
        "metrics_rf = evaluate_model(pred_rf)\n",
        "metrics_lr = evaluate_model(pred_lr)\n",
        "\n",
        "print(\"‚úÖ NAIVE BAYES\")\n",
        "print(metrics_nb)\n",
        "print(\"\\n‚úÖ RANDOM FOREST\")\n",
        "print(metrics_rf)\n",
        "print(\"\\n‚úÖ LOGISTIC REGRESSION\")\n",
        "print(metrics_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUvlko00x3LV",
        "outputId": "58ab0a1c-c4af-4079-aa96-ae4a33efa6fa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ NAIVE BAYES\n",
            "{'Accuracy': 0.9383301707779886, 'Precision': 0.9548232465390606, 'Recall': 0.9383301707779886, 'F1-score': 0.9425531436838295}\n",
            "\n",
            "‚úÖ RANDOM FOREST\n",
            "{'Accuracy': 0.8709677419354839, 'Precision': 0.8876804915514593, 'Recall': 0.8709677419354839, 'F1-score': 0.8145033542839207}\n",
            "\n",
            "‚úÖ LOGISTIC REGRESSION\n",
            "{'Accuracy': 0.9724857685009488, 'Precision': 0.9733319113572292, 'Recall': 0.9724857685009488, 'F1-score': 0.9711111401239485}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abbc866e",
        "outputId": "d72756bb-647c-44bf-9b5e-39a569f1109b"
      },
      "source": [
        "new_emails = [\n",
        "    (\"Congratulations! You won a free iPhone!\",),\n",
        "    (\"Bonjour, voici le rapport demand√© pour votre r√©union.\",)\n",
        "]\n",
        "\n",
        "new_df = spark.createDataFrame(new_emails, [\"v2\"])\n",
        "\n",
        "new_df_prepared = model.transform(new_df)\n",
        "\n",
        "predictions = lr_model.transform(new_df_prepared)\n",
        "\n",
        "predictions.select(\"v2\", \"prediction\", \"probability\").show(truncate=False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------+----------+-----------------------------------------+\n",
            "|v2                                                   |prediction|probability                              |\n",
            "+-----------------------------------------------------+----------+-----------------------------------------+\n",
            "|Congratulations! You won a free iPhone!              |0.0       |[0.9831558705874133,0.016844129412586728]|\n",
            "|Bonjour, voici le rapport demand√© pour votre r√©union.|0.0       |[0.9788631461216026,0.021136853878397366]|\n",
            "+-----------------------------------------------------+----------+-----------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sauvegarde du pipeline et du mod√®le LR\n",
        "model.write().overwrite().save(\"pipeline_model\")\n",
        "lr_model.write().overwrite().save(\"lr_model\")\n",
        "\n",
        "print(\"‚úÖ Pipeline et mod√®le sauvegard√©s avec succ√®s !\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIscc9TJ2aqY",
        "outputId": "b4c717a8-a3c2-4b03-8b94-0895e5186c69"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Pipeline et mod√®le sauvegard√©s avec succ√®s !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio pyspark\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPRKdoBz43HZ",
        "outputId": "8f88fb03-4e09-4884-8fcb-3e65ffe0233a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.1)\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.121.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.4)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.4)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.49.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV into pandas first\n",
        "df = pd.read_csv(\"/content/spam2.csv\", encoding='latin-1')\n",
        "\n",
        "# Check the columns\n",
        "print(df.head())\n",
        "print(df.columns)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHOewcM2_g8z",
        "outputId": "fcb0407e-5901-43c9-ebab-82e9f768e8f7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                              COMMENT_ID  \\\n",
            "0    z13lgffb5w3ddx1ul22qy1wxspy5cpkz504   \n",
            "1      z123dbgb0mqjfxbtz22ucjc5jvzcv3ykj   \n",
            "2  z12quxxp2vutflkxv04cihggzt2azl34pms0k   \n",
            "3      z12icv3ysqvlwth2c23eddlykyqut5z1h   \n",
            "4      z133stly3kete3tly22petvwdpmghrlli   \n",
            "\n",
            "                                              AUTHOR  \\\n",
            "0                                         dharma pal   \n",
            "1                                      Tiza Arellano   \n",
            "2  Pr√É¬¨√É¬±√É¬ße√Ö¬õ√Ö¬õ √É¬Çli√Ö¬õ √Ö¬Å√É¬∏v√É¬™ D√É¬∏m√É¬≠√É¬±√É¬∏ M√É¬¢√Ñ¬ëi...   \n",
            "3                                      Eric Gonzalez   \n",
            "4                                     Analena L√É¬≥pez   \n",
            "\n",
            "                         DATE  \\\n",
            "0  2015-05-29T02:30:18.971000   \n",
            "1  2015-05-29T00:14:48.748000   \n",
            "2  2015-05-28T21:00:08.607000   \n",
            "3  2015-05-28T20:47:12.193000   \n",
            "4  2015-05-28T17:08:29.827000   \n",
            "\n",
            "                                             CONTENT  CLASS  \n",
            "0                                       Nice song√Ø¬ª¬ø      0  \n",
            "1                                    I love song √Ø¬ª¬ø      0  \n",
            "2                                    I love song √Ø¬ª¬ø      0  \n",
            "3  860,000,000 lets make it first female to reach...      0  \n",
            "4                    shakira is best for worldcup√Ø¬ª¬ø      0  \n",
            "Index(['COMMENT_ID', 'AUTHOR', 'DATE', 'CONTENT', 'CLASS'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_col = \"CONTENT\"   # Change if needed\n",
        "label_col = \"CLASS\"    # Change if needed\n",
        "\n",
        "assert text_col in df.columns, f\"'{text_col}' not found in CSV!\"\n",
        "assert label_col in df.columns, f\"'{label_col}' not found in CSV!\"\n",
        "\n",
        "# Convert to Spark DataFrame\n",
        "sdf = spark.createDataFrame(df)\n",
        "\n",
        "# Check a few rows\n",
        "sdf.select(text_col, label_col).show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6MRo4X5BAA7",
        "outputId": "ccc54df0-fa46-4d0d-dd4d-e673e24d6aaf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------------------------------------------+-----+\n",
            "|CONTENT                                                                                 |CLASS|\n",
            "+----------------------------------------------------------------------------------------+-----+\n",
            "|Nice song√Ø¬ª¬ø                                                                            |0    |\n",
            "|I love song √Ø¬ª¬ø                                                                         |0    |\n",
            "|I love song √Ø¬ª¬ø                                                                         |0    |\n",
            "|860,000,000 lets make it first female to reach one billion!! Share it and replay it! √Ø¬ª¬ø|0    |\n",
            "|shakira is best for worldcup√Ø¬ª¬ø                                                         |0    |\n",
            "+----------------------------------------------------------------------------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(inputCol=text_col, outputCol=\"tokens\")\n",
        "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered\")\n",
        "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=20000)\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "indexer = StringIndexer(inputCol=label_col, outputCol=\"label\")\n"
      ],
      "metadata": {
        "id": "HYUnRU_6Bi9j"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = sdf.randomSplit([0.8, 0.2], seed=42)\n"
      ],
      "metadata": {
        "id": "GOsoevwuBmxn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
        "from pyspark.ml.classification import (\n",
        "    LogisticRegression,\n",
        "    NaiveBayes,\n",
        "    RandomForestClassifier,\n",
        "    DecisionTreeClassifier\n",
        ")\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "import pandas as pd\n",
        "\n",
        "spark = SparkSession.builder.appName(\"YouTube_Spam_MultiModel\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "8HGgqvyIBz5Z"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=50, regParam=0.01),\n",
        "    \"Naive Bayes\": NaiveBayes(featuresCol=\"features\", labelCol=\"label\", modelType=\"multinomial\"),\n",
        "    \"Random Forest\": RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=50, maxDepth=10),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\", maxDepth=10)\n",
        "}\n"
      ],
      "metadata": {
        "id": "GLD5Zo82Boli"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, clf in models.items():\n",
        "    pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idf, indexer, clf])\n",
        "    model = pipeline.fit(train_df)\n",
        "    preds = model.transform(test_df)\n",
        "\n",
        "    acc = evaluator.evaluate(preds, {evaluator.metricName: \"accuracy\"})\n",
        "    f1 = evaluator.evaluate(preds, {evaluator.metricName: \"f1\"})\n",
        "    precision = evaluator.evaluate(preds, {evaluator.metricName: \"weightedPrecision\"})\n",
        "    recall = evaluator.evaluate(preds, {evaluator.metricName: \"weightedRecall\"})\n",
        "\n",
        "    results.append((name, acc, precision, recall, f1))\n",
        "    print(f\"‚úÖ {name} trained ‚Äî Accuracy: {acc:.4f}, F1: {f1:.4f}\")\n",
        "\n",
        "# Convert to Pandas for easy viewing\n",
        "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"])\n",
        "results_df.sort_values(by=\"F1-score\", ascending=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "1p3Lmj90BotV",
        "outputId": "968896cd-11fa-409b-e184-5ac9f2683af6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Logistic Regression trained ‚Äî Accuracy: 0.8571, F1: 0.8561\n",
            "‚úÖ Naive Bayes trained ‚Äî Accuracy: 0.8254, F1: 0.8245\n",
            "‚úÖ Random Forest trained ‚Äî Accuracy: 0.7460, F1: 0.7273\n",
            "‚úÖ Decision Tree trained ‚Äî Accuracy: 0.9048, F1: 0.9043\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Model  Accuracy  Precision    Recall  F1-score\n",
              "3        Decision Tree  0.904762   0.911229  0.904762  0.904279\n",
              "0  Logistic Regression  0.857143   0.866053  0.857143  0.856053\n",
              "1          Naive Bayes  0.825397   0.834215  0.825397  0.824513\n",
              "2        Random Forest  0.746032   0.830688  0.746032  0.727260"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d718414-bc14-4e2c-9a23-860df5080616\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.904762</td>\n",
              "      <td>0.911229</td>\n",
              "      <td>0.904762</td>\n",
              "      <td>0.904279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.866053</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.856053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.825397</td>\n",
              "      <td>0.834215</td>\n",
              "      <td>0.825397</td>\n",
              "      <td>0.824513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.746032</td>\n",
              "      <td>0.830688</td>\n",
              "      <td>0.746032</td>\n",
              "      <td>0.727260</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d718414-bc14-4e2c-9a23-860df5080616')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4d718414-bc14-4e2c-9a23-860df5080616 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4d718414-bc14-4e2c-9a23-860df5080616');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a11ee5d8-062a-4a60-8cf4-561e3e357b20\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a11ee5d8-062a-4a60-8cf4-561e3e357b20')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a11ee5d8-062a-4a60-8cf4-561e3e357b20 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Logistic Regression\",\n          \"Random Forest\",\n          \"Decision Tree\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0667170381635899,\n        \"min\": 0.746031746031746,\n        \"max\": 0.9047619047619048,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8571428571428571,\n          0.746031746031746,\n          0.9047619047619048\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.037344716497504704,\n        \"min\": 0.8306878306878307,\n        \"max\": 0.9112286890064668,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8660528660528661,\n          0.8306878306878307,\n          0.9112286890064668\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06671703816358986,\n        \"min\": 0.746031746031746,\n        \"max\": 0.9047619047619047,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8571428571428571,\n          0.746031746031746,\n          0.9047619047619047\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1-score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07475766225489232,\n        \"min\": 0.7272601794340925,\n        \"max\": 0.9042789529604945,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8560531764193091,\n          0.7272601794340925,\n          0.9042789529604945\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_name = results_df.sort_values(by=\"F1-score\", ascending=False).iloc[0][\"Model\"]\n",
        "print(f\"üèÜ Best Model: {best_model_name}\")\n",
        "\n",
        "# Refit the best model pipeline and save\n",
        "best_clf = models[best_model_name]\n",
        "best_pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idf, indexer, best_clf])\n",
        "best_model = best_pipeline.fit(sdf)\n",
        "\n",
        "best_model.write().overwrite().save(\"/content/pipeline_model_youtube\")\n",
        "print(\"‚úÖ Saved best model to /content/pipeline_model_youtube\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSWP5Kb9CANb",
        "outputId": "70e5031b-e3d5-4638-a73c-ff8b61e063bc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÜ Best Model: Decision Tree\n",
            "‚úÖ Saved best model to /content/pipeline_model_youtube\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_comments = [\n",
        "    (\"Check my channel for free iPhone!\",),\n",
        "    (\"Nice content bro!\",),\n",
        "    (\"Click here for giveaway!\",)\n",
        "]\n",
        "\n",
        "test_comments = spark.createDataFrame(sample_comments, [text_col])\n",
        "preds = best_model.transform(test_comments)\n",
        "preds.select(text_col, \"prediction\", \"probability\").show(truncate=False)\n"
      ],
      "metadata": {
        "id": "vo1shtmkCOzg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "862e79b8-bb9d-415c-bf38-08b08916ea57"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------+----------+----------------------------------------+\n",
            "|CONTENT                          |prediction|probability                             |\n",
            "+---------------------------------+----------+----------------------------------------+\n",
            "|Check my channel for free iPhone!|1.0       |[0.0,1.0]                               |\n",
            "|Nice content bro!                |0.0       |[0.9018691588785047,0.09813084112149532]|\n",
            "|Click here for giveaway!         |0.0       |[0.9018691588785047,0.09813084112149532]|\n",
            "+---------------------------------+----------+----------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import PipelineModel\n",
        "from pyspark.ml.classification import (\n",
        "    NaiveBayesModel,\n",
        "    RandomForestClassificationModel,\n",
        "    LogisticRegressionModel\n",
        ")\n",
        "\n",
        "# --- Initialize Spark ---\n",
        "spark = SparkSession.builder.appName(\"Spam Detection Gradio\").getOrCreate()\n",
        "\n",
        "# --- Load all models ---\n",
        "# Adjusting the model loading based on what was actually saved:\n",
        "# For Email Spam Detection:\n",
        "#   - pipeline_model: The feature engineering pipeline (Tokenizer, StopWordsRemover, HashingTF, IDF)\n",
        "#   - lr_model: The Logistic Regression classifier model\n",
        "# Other email models (NB, RF) were trained but not explicitly saved as separate models for reuse here.\n",
        "#\n",
        "# For YouTube Comment Spam Detection:\n",
        "#   - pipeline_model_youtube: A *full* PipelineModel that includes feature engineering AND the best classifier (Decision Tree).\n",
        "models = {\n",
        "    \"Email Spam Detection\": {\n",
        "        \"feature_pipeline\": PipelineModel.load(\"/content/pipeline_model\"),\n",
        "        \"classifier\": { # Store individual classifiers that were saved\n",
        "            \"Logistic Regression\": LogisticRegressionModel.load(\"/content/lr_model\")\n",
        "            # Naive Bayes and Random Forest models for email were not explicitly saved separately\n",
        "        },\n",
        "        \"input_col\": \"v2\"\n",
        "    },\n",
        "    \"YouTube Comment Spam Detection\": {\n",
        "        \"full_pipeline\": PipelineModel.load(\"/content/pipeline_model_youtube\"), # This is the complete pipeline with the best classifier (Decision Tree)\n",
        "        \"input_col\": \"CONTENT\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# --- Prediction function ---\n",
        "def predict_text(text, detection_type, model_choice):\n",
        "    if not text.strip():\n",
        "        return \"‚ö†Ô∏è Veuillez entrer un texte.\", None\n",
        "\n",
        "    try:\n",
        "        model_set = models[detection_type]\n",
        "    except KeyError:\n",
        "        return \"‚ùå Type de d√©tection non trouv√©.\", None\n",
        "\n",
        "    input_col = model_set[\"input_col\"]\n",
        "\n",
        "    try:\n",
        "        # Create a Spark DataFrame from the input text\n",
        "        new_df = spark.createDataFrame([(text,)], [input_col])\n",
        "        preds = None\n",
        "\n",
        "        if detection_type == \"Email Spam Detection\":\n",
        "            # For email, first apply feature engineering pipeline\n",
        "            feature_pipeline = model_set[\"feature_pipeline\"]\n",
        "            new_df_prepared = feature_pipeline.transform(new_df)\n",
        "\n",
        "            # Select the appropriate classifier based on user choice\n",
        "            classifier_to_use = model_set[\"classifier\"].get(model_choice)\n",
        "            if classifier_to_use is None:\n",
        "                return f\"‚ùå Mod√®le '{model_choice}' non disponible pour la d√©tection d'emails. Seul 'Logistic Regression' a √©t√© sauvegard√© s√©par√©ment.\", None\n",
        "\n",
        "            preds = classifier_to_use.transform(new_df_prepared)\n",
        "\n",
        "        elif detection_type == \"YouTube Comment Spam Detection\":\n",
        "            # For YouTube, use the pre-saved full pipeline which includes feature engineering and the best classifier (Decision Tree)\n",
        "            # The 'model_choice' from the UI is effectively ignored here as only one full pipeline was saved for YouTube comments.\n",
        "            full_pipeline_youtube = model_set[\"full_pipeline\"]\n",
        "            preds = full_pipeline_youtube.transform(new_df)\n",
        "        else:\n",
        "            return \"‚ùå Type de d√©tection inconnu.\", None\n",
        "\n",
        "        if preds is None:\n",
        "            return \"‚ùå Erreur interne: Aucune pr√©diction g√©n√©r√©e.\", None\n",
        "\n",
        "        # Get the prediction result\n",
        "        pred_row = preds.select(\"prediction\", \"probability\").collect()[0]\n",
        "\n",
        "        # Extract prediction and probability\n",
        "        prob = pred_row[\"probability\"]\n",
        "        predicted_class_prob = float(prob[int(pred_row[\"prediction\"])])\n",
        "\n",
        "        label = \"üö® Spam d√©tect√© !\" if pred_row[\"prediction\"] == 1.0 else \"üì¨ Message normal\"\n",
        "        return label, f\"Probabilit√© de la classe pr√©dite ({'Spam' if pred_row['prediction'] == 1.0 else 'Normal'}) : {predicted_class_prob:.3f}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Erreur de pr√©diction : {str(e)}\", None\n",
        "\n",
        "# --- Interface Gradio ---\n",
        "interface = gr.Interface(\n",
        "    fn=predict_text,\n",
        "    inputs=[\n",
        "        gr.Textbox(\n",
        "            label=\"üí¨ Entrez le texte √† analyser\",\n",
        "            lines=5,\n",
        "            placeholder=\"Exemple : Check out my channel for free iPhones!\"\n",
        "        ),\n",
        "        gr.Radio(\n",
        "            [\"Email Spam Detection\", \"YouTube Comment Spam Detection\"],\n",
        "            label=\"üìÇ Type de d√©tection\",\n",
        "            value=\"Email Spam Detection\"\n",
        "        ),\n",
        "        gr.Radio(\n",
        "            [\"Naive Bayes\", \"Random Forest\", \"Logistic Regression\"],\n",
        "            label=\"üß† Choisissez le mod√®le\" # Note: For YouTube, this choice is currently ignored as only one full pipeline is used.\n",
        "        ),\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"R√©sultat de la pr√©diction\"),\n",
        "        gr.Textbox(label=\"D√©tails de la probabilit√©\")\n",
        "    ],\n",
        "    title=\"üìßüé• D√©tection de Spam (Email & YouTube)\",\n",
        "    description=\"Utilisez des mod√®les PySpark pour d√©tecter les spams dans des emails ou des commentaires YouTube.\",\n",
        "    theme=\"soft\"\n",
        ")\n",
        "\n",
        "# --- Launch app ---\n",
        "interface.launch(share=True)\n"
      ],
      "metadata": {
        "id": "FgO_FICICzn0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "outputId": "e601e6e2-dedd-422f-e899-8b0d37f145dc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8640ad76ad488ffa06.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8640ad76ad488ffa06.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content\n"
      ],
      "metadata": {
        "id": "nw_DDUIJFGUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e03236d-d04e-4197-e011-82cd91e07fad"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lr_model\tpipeline_model_youtube\tspam2.csv\n",
            "pipeline_model\tsample_data\t\tspam.csv\n"
          ]
        }
      ]
    }
  ]
}